sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6458                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6445                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6416                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6394                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6394 
Self-heal Daemon on localhost               N/A       N/A        Y       6415 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2647 
Self-heal Daemon on localhost               N/A       N/A        Y       2657 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
702578da-8c12-4e99-95b0-dd6127a91b2e	ClusterMachine3.ex1.gr4	Connected 
869a7715-2cb1-4109-bdb7-e2f8682d1752	ClusterMachine2.ex1.gr4	Connected 
97786405-cde7-443e-905c-2287ca259ef8	ClusterMachine1.ex1.gr4	Connected 
3bf7ea61-727f-47fb-9204-0112079992ea	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2647 
Self-heal Daemon on localhost               N/A       N/A        Y       2657 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
702578da-8c12-4e99-95b0-dd6127a91b2e	ClusterMachine3.ex1.gr4	Connected 
869a7715-2cb1-4109-bdb7-e2f8682d1752	ClusterMachine2.ex1.gr4	Connected 
97786405-cde7-443e-905c-2287ca259ef8	ClusterMachine1.ex1.gr4	Connected 
3bf7ea61-727f-47fb-9204-0112079992ea	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
b77e91ca-c20b-46e1-9503-d67d3c0d0394	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
a627712d-65b1-49e1-840f-dd71aedf55a9	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6433                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6392                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6387                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6356                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6433 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6392 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6387 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6356 
Self-heal Daemon on localhost               N/A       N/A        Y       6377 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6408 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6413 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6454 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: b656b884-4f20-455d-a485-bf195cbc8964
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
a627712d-65b1-49e1-840f-dd71aedf55a9	ClusterMachine3.ex1.gr4	Connected 
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	ClusterMachine2.ex1.gr4	Connected 
b77e91ca-c20b-46e1-9503-d67d3c0d0394	ClusterMachine1.ex1.gr4	Connected 
468c9ed3-cbe0-475e-bcad-dea498e649d7	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2752 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2645 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6387 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2649 
Self-heal Daemon on localhost               N/A       N/A        Y       2661 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6408 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       2763 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       2653 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: b656b884-4f20-455d-a485-bf195cbc8964
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
performance.client-io-threads: off
nfs.disable: on
transport.address-family: inet
sudo gluster pool list
UUID					Hostname               	State
a627712d-65b1-49e1-840f-dd71aedf55a9	ClusterMachine3.ex1.gr4	Connected 
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	ClusterMachine2.ex1.gr4	Connected 
b77e91ca-c20b-46e1-9503-d67d3c0d0394	ClusterMachine1.ex1.gr4	Connected 
468c9ed3-cbe0-475e-bcad-dea498e649d7	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
39eb92b8-7f6f-4729-b8fe-10327aeea945	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
f668ffea-7b66-4ff5-bea7-660bff3e0949	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
713af489-7570-452d-b897-98747bb35ce1	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6388                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6382                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6388                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6328                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6388 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6382 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6388 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6328 
Self-heal Daemon on localhost               N/A       N/A        Y       6349 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6409 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6403 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6409 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 8e857bfe-ac3a-417e-98d3-e259d9e2f081
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
713af489-7570-452d-b897-98747bb35ce1	ClusterMachine3.ex1.gr4	Connected 
f668ffea-7b66-4ff5-bea7-660bff3e0949	ClusterMachine2.ex1.gr4	Connected 
39eb92b8-7f6f-4729-b8fe-10327aeea945	ClusterMachine1.ex1.gr4	Connected 
ed1d5489-53f5-4920-80e4-b4e8ef803427	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
f1e19fd3-9438-4a09-8e99-e521416a74f0	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
3fd22ae7-f14b-4d09-a2c1-78f8b5e4442e	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
0102fb30-a080-4ad6-9d41-48be697d6f0e	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
02b45a70-1b1f-4289-a1ff-c8fc87c65035	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
63171d7d-5c6a-4b54-8a8b-ed7cadbc899a	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
0dcee6e7-413c-4232-9947-b3daf3547195	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
be92df36-31e6-41b0-adc5-b47e3d3fde9c	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6598                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6385                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6312                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6340                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6598 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6385 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6312 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6340 
Self-heal Daemon on localhost               N/A       N/A        Y       6361 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6333 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6619 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6406 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: c6dc40e3-dc4d-48dc-b69b-8b85e26b4f6c
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
be92df36-31e6-41b0-adc5-b47e3d3fde9c	ClusterMachine3.ex1.gr4	Connected 
0dcee6e7-413c-4232-9947-b3daf3547195	ClusterMachine2.ex1.gr4	Connected 
63171d7d-5c6a-4b54-8a8b-ed7cadbc899a	ClusterMachine1.ex1.gr4	Connected 
5a917507-65f5-4a29-8d68-8c076e73804a	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
2f417786-f987-4de4-b97b-f35b22e7faa5	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
a3e1efd1-9d5a-405e-9dcf-f5e6a30a8d9d	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
b8bde649-8f49-43a7-be9c-758d5b0d9d36	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
d169ec06-9ce4-4251-98a5-204fa895dcc2	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname               	State
9e180f76-3585-430d-b360-31e9b58c10c9	ClusterMachine4.ex1.gr4	Connected 
d169ec06-9ce4-4251-98a5-204fa895dcc2	ClusterMachine3.ex1.gr4	Connected 
39404e23-0cfa-4f24-abd0-087df2615536	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
4e11d6cf-37e3-4553-ab79-416d81d41f99	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
843bbc6f-f3bc-4092-b3c6-94ad2cad74c3	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
c420c6a5-7fb9-4c56-bb73-8393d78e173f	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6687                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6678                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6624                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6559                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6687 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6678 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6624 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6559 
Self-heal Daemon on localhost               N/A       N/A        Y       6580 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6708 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6645 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6699 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 3d3fc9c2-ee70-4ebf-988e-8012b274ac93
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
4e11d6cf-37e3-4553-ab79-416d81d41f99	ClusterMachine3.ex1.gr4	Connected 
c420c6a5-7fb9-4c56-bb73-8393d78e173f	ClusterMachine2.ex1.gr4	Connected 
843bbc6f-f3bc-4092-b3c6-94ad2cad74c3	ClusterMachine1.ex1.gr4	Connected 
3d443e4c-8184-4911-9a7a-47e1d7f17699	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
97309dd3-5ad9-4ba2-92e3-15edc5277b09	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
425efec7-d46c-4f69-98bb-478ef090f302	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
f3a4c76a-7225-4c97-8833-f09deb1749ee	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname               	State
71cacd0c-f5bc-4646-be85-f73d39eb4b65	ClusterMachine4.ex1.gr4	Connected 
f3a4c76a-7225-4c97-8833-f09deb1749ee	ClusterMachine1.ex1.gr4	Connected 
30f35c7b-14f8-43e8-bb9e-bd4eee19c7eb	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
593dc506-338b-4db8-a8ce-6eb1d6377424	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
9572233e-b978-4b3b-85aa-45274c1bf785	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
cb0a7eea-17fa-47e5-a988-3179c6ac910c	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
6315970c-587b-4ce4-bcca-89259cd2f97c	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6670                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6664                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6679                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6564                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6670 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6664 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6679 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6564 
Self-heal Daemon on localhost               N/A       N/A        Y       6585 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6685 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6691 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6700 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 570f941f-5188-4ca8-a0af-a56a4744f382
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
6315970c-587b-4ce4-bcca-89259cd2f97c	ClusterMachine3.ex1.gr4	Connected 
cb0a7eea-17fa-47e5-a988-3179c6ac910c	ClusterMachine2.ex1.gr4	Connected 
9572233e-b978-4b3b-85aa-45274c1bf785	ClusterMachine1.ex1.gr4	Connected 
4e55972c-e4ed-48b5-8fff-35a6526c741f	localhost              	Connected 
