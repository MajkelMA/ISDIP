sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6458                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6445                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6416                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6394                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6394 
Self-heal Daemon on localhost               N/A       N/A        Y       6415 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2647 
Self-heal Daemon on localhost               N/A       N/A        Y       2657 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
702578da-8c12-4e99-95b0-dd6127a91b2e	ClusterMachine3.ex1.gr4	Connected 
869a7715-2cb1-4109-bdb7-e2f8682d1752	ClusterMachine2.ex1.gr4	Connected 
97786405-cde7-443e-905c-2287ca259ef8	ClusterMachine1.ex1.gr4	Connected 
3bf7ea61-727f-47fb-9204-0112079992ea	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6445 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6416 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2647 
Self-heal Daemon on localhost               N/A       N/A        Y       2657 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6437 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6466 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 731f1f38-44da-4491-9f8a-f0fefc1efb80
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
702578da-8c12-4e99-95b0-dd6127a91b2e	ClusterMachine3.ex1.gr4	Connected 
869a7715-2cb1-4109-bdb7-e2f8682d1752	ClusterMachine2.ex1.gr4	Connected 
97786405-cde7-443e-905c-2287ca259ef8	ClusterMachine1.ex1.gr4	Connected 
3bf7ea61-727f-47fb-9204-0112079992ea	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
b77e91ca-c20b-46e1-9503-d67d3c0d0394	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
a627712d-65b1-49e1-840f-dd71aedf55a9	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6433                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6392                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6387                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6356                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6433 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6392 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6387 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6356 
Self-heal Daemon on localhost               N/A       N/A        Y       6377 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6408 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6413 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6454 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: b656b884-4f20-455d-a485-bf195cbc8964
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
a627712d-65b1-49e1-840f-dd71aedf55a9	ClusterMachine3.ex1.gr4	Connected 
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	ClusterMachine2.ex1.gr4	Connected 
b77e91ca-c20b-46e1-9503-d67d3c0d0394	ClusterMachine1.ex1.gr4	Connected 
468c9ed3-cbe0-475e-bcad-dea498e649d7	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2752 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2645 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6387 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2649 
Self-heal Daemon on localhost               N/A       N/A        Y       2661 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6408 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       2763 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       2653 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: b656b884-4f20-455d-a485-bf195cbc8964
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
performance.client-io-threads: off
nfs.disable: on
transport.address-family: inet
sudo gluster pool list
UUID					Hostname               	State
a627712d-65b1-49e1-840f-dd71aedf55a9	ClusterMachine3.ex1.gr4	Connected 
8b7d4752-6300-4adc-b9d0-c7e2f5357e52	ClusterMachine2.ex1.gr4	Connected 
b77e91ca-c20b-46e1-9503-d67d3c0d0394	ClusterMachine1.ex1.gr4	Connected 
468c9ed3-cbe0-475e-bcad-dea498e649d7	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
39eb92b8-7f6f-4729-b8fe-10327aeea945	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
f668ffea-7b66-4ff5-bea7-660bff3e0949	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
713af489-7570-452d-b897-98747bb35ce1	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6388                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6382                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6388                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6328                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6388 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6382 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6388 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6328 
Self-heal Daemon on localhost               N/A       N/A        Y       6349 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6409 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6403 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6409 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 8e857bfe-ac3a-417e-98d3-e259d9e2f081
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
713af489-7570-452d-b897-98747bb35ce1	ClusterMachine3.ex1.gr4	Connected 
f668ffea-7b66-4ff5-bea7-660bff3e0949	ClusterMachine2.ex1.gr4	Connected 
39eb92b8-7f6f-4729-b8fe-10327aeea945	ClusterMachine1.ex1.gr4	Connected 
ed1d5489-53f5-4920-80e4-b4e8ef803427	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
f1e19fd3-9438-4a09-8e99-e521416a74f0	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
3fd22ae7-f14b-4d09-a2c1-78f8b5e4442e	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
0102fb30-a080-4ad6-9d41-48be697d6f0e	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
02b45a70-1b1f-4289-a1ff-c8fc87c65035	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
63171d7d-5c6a-4b54-8a8b-ed7cadbc899a	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
0dcee6e7-413c-4232-9947-b3daf3547195	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
be92df36-31e6-41b0-adc5-b47e3d3fde9c	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6598                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6385                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6312                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6340                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6598 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6385 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6312 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6340 
Self-heal Daemon on localhost               N/A       N/A        Y       6361 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6333 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6619 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6406 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: c6dc40e3-dc4d-48dc-b69b-8b85e26b4f6c
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
be92df36-31e6-41b0-adc5-b47e3d3fde9c	ClusterMachine3.ex1.gr4	Connected 
0dcee6e7-413c-4232-9947-b3daf3547195	ClusterMachine2.ex1.gr4	Connected 
63171d7d-5c6a-4b54-8a8b-ed7cadbc899a	ClusterMachine1.ex1.gr4	Connected 
5a917507-65f5-4a29-8d68-8c076e73804a	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
2f417786-f987-4de4-b97b-f35b22e7faa5	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
a3e1efd1-9d5a-405e-9dcf-f5e6a30a8d9d	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
b8bde649-8f49-43a7-be9c-758d5b0d9d36	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
31b32037-7515-46e3-a723-524cea94edcb	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
284c782d-a14d-488b-8976-ceb30b47be34	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
57d3d67b-46c9-4f5a-b892-c393157c11e8	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7029                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6988                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6951                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6912                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7029 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6988 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6951 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6912 
Self-heal Daemon on localhost               N/A       N/A        Y       6933 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       7050 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       7009 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6972 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: d5496a44-2bee-4439-8ab8-9d71fd79afa1
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
57d3d67b-46c9-4f5a-b892-c393157c11e8	ClusterMachine3.ex1.gr4	Connected 
284c782d-a14d-488b-8976-ceb30b47be34	ClusterMachine2.ex1.gr4	Connected 
31b32037-7515-46e3-a723-524cea94edcb	ClusterMachine1.ex1.gr4	Connected 
bd92dcca-7d6d-4dec-a34d-d5a3babe4e05	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7029 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6988 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6951 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6912 
Self-heal Daemon on localhost               N/A       N/A        Y       6933 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       7009 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6972 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       7050 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: d5496a44-2bee-4439-8ab8-9d71fd79afa1
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
57d3d67b-46c9-4f5a-b892-c393157c11e8	ClusterMachine3.ex1.gr4	Connected 
284c782d-a14d-488b-8976-ceb30b47be34	ClusterMachine2.ex1.gr4	Connected 
31b32037-7515-46e3-a723-524cea94edcb	ClusterMachine1.ex1.gr4	Connected 
bd92dcca-7d6d-4dec-a34d-d5a3babe4e05	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
8502a901-1ee4-43de-9ee3-4b4e5addc84a	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
2ce31002-a00c-4fde-9072-f4b9f75ed782	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
5865e5bf-ab27-4014-90d3-d33339bcf529	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6956                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6959                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7006                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6930                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6956 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6959 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7006 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6930 
Self-heal Daemon on localhost               N/A       N/A        Y       6951 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       7027 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6977 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6980 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 41231f96-961b-4903-9e63-ad7cccd9eb85
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
5865e5bf-ab27-4014-90d3-d33339bcf529	ClusterMachine3.ex1.gr4	Connected 
2ce31002-a00c-4fde-9072-f4b9f75ed782	ClusterMachine2.ex1.gr4	Connected 
8502a901-1ee4-43de-9ee3-4b4e5addc84a	ClusterMachine1.ex1.gr4	Connected 
d4bdf3a9-09dd-417b-a19d-8d3d89147f48	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
7e5d1092-c683-4fde-a02d-9847b10732fc	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
24ad5ff4-ffe3-4237-88e6-a92c5e5d9f6c	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
69e254cc-0497-4834-a1be-21a735f69aa8	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7193                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7110                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7106                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6966                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7193 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7110 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7106 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6966 
Self-heal Daemon on localhost               N/A       N/A        Y       6987 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       7131 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       7127 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       7214 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 467d2aba-d008-407b-8853-236246cac4c9
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
69e254cc-0497-4834-a1be-21a735f69aa8	ClusterMachine3.ex1.gr4	Connected 
24ad5ff4-ffe3-4237-88e6-a92c5e5d9f6c	ClusterMachine2.ex1.gr4	Connected 
7e5d1092-c683-4fde-a02d-9847b10732fc	ClusterMachine1.ex1.gr4	Connected 
78d468d3-adca-4a4d-9a52-741ebb4cbf4d	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
360e503d-e627-41ef-b1ee-8f248a65156a	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
40415269-f3e8-43e0-a4b6-f5fef0440e52	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
25323d66-1494-4b62-ab0f-ac46207bd7b1	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
5627534a-7a81-4b96-8812-b594eea3a867	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7041                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7002                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 7009                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6999                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7041 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7002 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       7009 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6999 
Self-heal Daemon on localhost               N/A       N/A        Y       7020 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       7023 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       7030 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       7062 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: be8af13b-fb59-4851-84f8-45548d62ae7d
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
5627534a-7a81-4b96-8812-b594eea3a867	ClusterMachine3.ex1.gr4	Connected 
25323d66-1494-4b62-ab0f-ac46207bd7b1	ClusterMachine2.ex1.gr4	Connected 
40415269-f3e8-43e0-a4b6-f5fef0440e52	ClusterMachine1.ex1.gr4	Connected 
f5902042-6236-4b45-b0b9-c0d060a40fed	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       3027 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       3088 
Self-heal Daemon on localhost               N/A       N/A        Y       3100 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       3052 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: be8af13b-fb59-4851-84f8-45548d62ae7d
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
performance.client-io-threads: off
nfs.disable: on
transport.address-family: inet
features.ctime: on
sudo gluster pool list
UUID					Hostname               	State
5627534a-7a81-4b96-8812-b594eea3a867	ClusterMachine3.ex1.gr4	Disconnected 
25323d66-1494-4b62-ab0f-ac46207bd7b1	ClusterMachine2.ex1.gr4	Disconnected 
40415269-f3e8-43e0-a4b6-f5fef0440e52	ClusterMachine1.ex1.gr4	Connected 
f5902042-6236-4b45-b0b9-c0d060a40fed	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6145 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2910 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2925 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2911 
Self-heal Daemon on localhost               N/A       N/A        Y       2920 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6156 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       2935 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       2928 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: be8af13b-fb59-4851-84f8-45548d62ae7d
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
5627534a-7a81-4b96-8812-b594eea3a867	ClusterMachine3.ex1.gr4	Connected 
25323d66-1494-4b62-ab0f-ac46207bd7b1	ClusterMachine2.ex1.gr4	Connected 
40415269-f3e8-43e0-a4b6-f5fef0440e52	ClusterMachine1.ex1.gr4	Connected 
f5902042-6236-4b45-b0b9-c0d060a40fed	localhost              	Connected 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2891 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2910 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2887 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       2888 
Self-heal Daemon on localhost               N/A       N/A        Y       2901 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       2928 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       2901 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       2898 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: be8af13b-fb59-4851-84f8-45548d62ae7d
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
performance.client-io-threads: off
nfs.disable: on
transport.address-family: inet
features.ctime: on
sudo gluster pool list
UUID					Hostname               	State
5627534a-7a81-4b96-8812-b594eea3a867	ClusterMachine3.ex1.gr4	Connected 
25323d66-1494-4b62-ab0f-ac46207bd7b1	ClusterMachine2.ex1.gr4	Connected 
40415269-f3e8-43e0-a4b6-f5fef0440e52	ClusterMachine1.ex1.gr4	Connected 
f5902042-6236-4b45-b0b9-c0d060a40fed	localhost              	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
7f554356-5b4c-401d-b81b-80cab6130739	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
23e03c5b-ec7b-4962-bb37-b8bb2420a026	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
sudo gluster volume status
sudo gluster volume info
sudo gluster pool list
UUID					Hostname 	State
372dc570-83ff-4922-bf1d-47fcc2fdd6f9	localhost	Connected 
sudo gluster volume status wol_grupa4 detail
Status of volume: wol_grupa4
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6458                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6422                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6414                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
------------------------------------------------------------------------------
Brick                : Brick ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
TCP Port             : 49152               
RDMA Port            : 0                   
Online               : Y                   
Pid                  : 6383                
File System          : xfs                 
Device               : /dev/sdb1           
Mount Options        : rw,seclabel,relatime,attr2,inode64,noquota
Inode Size           : 512                 
Disk Space Free      : 2.0GB               
Total Disk Space     : 2.0GB               
Inode Count          : 1048576             
Free Inodes          : 1048559             
 
sudo gluster volume status
Status of volume: wol_grupa4
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick ClusterMachine1.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6458 
Brick ClusterMachine2.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6422 
Brick ClusterMachine3.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6414 
Brick ClusterMachine4.ex1.gr4:/bricks/glust
er_brick/brick1                             49152     0          Y       6383 
Self-heal Daemon on localhost               N/A       N/A        Y       6404 
Self-heal Daemon on ClusterMachine3.ex1.gr4 N/A       N/A        Y       6435 
Self-heal Daemon on ClusterMachine1.ex1.gr4 N/A       N/A        Y       6479 
Self-heal Daemon on ClusterMachine2.ex1.gr4 N/A       N/A        Y       6443 
 
Task Status of Volume wol_grupa4
------------------------------------------------------------------------------
There are no active volume tasks
 
sudo gluster volume info
 
Volume Name: wol_grupa4
Type: Replicate
Volume ID: 3250a0cc-319c-4e34-b0d0-e6656b89ffc4
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: ClusterMachine1.ex1.gr4:/bricks/gluster_brick/brick1
Brick2: ClusterMachine2.ex1.gr4:/bricks/gluster_brick/brick1
Brick3: ClusterMachine3.ex1.gr4:/bricks/gluster_brick/brick1
Brick4: ClusterMachine4.ex1.gr4:/bricks/gluster_brick/brick1
Options Reconfigured:
features.ctime: on
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off
sudo gluster pool list
UUID					Hostname               	State
372dc570-83ff-4922-bf1d-47fcc2fdd6f9	ClusterMachine3.ex1.gr4	Connected 
23e03c5b-ec7b-4962-bb37-b8bb2420a026	ClusterMachine2.ex1.gr4	Connected 
7f554356-5b4c-401d-b81b-80cab6130739	ClusterMachine1.ex1.gr4	Connected 
ea35d583-b957-4650-8341-db1dde72ed91	localhost              	Connected 
